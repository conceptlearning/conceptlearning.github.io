---
layout: home
title: Home
home_title: Concept-based Interpretable Deep Learning
subtitle:
nav_title: Home
permalink: /
description:
---

<div style="margin: auto; text-align: center;">
  Tutorial held in conjunction with <a href="https://aaai.org/conference/aaai/aaai-25/">AAAI 2025</a><br>

  Pennsylvania Convention Center (Room 120A), Philadelphia, USA<br>

  February 25<sup>th</sup>, 2025 from 14:00 to 18:00<br>

</div>

## Introduction

As notoriously opaque deep neural networks (DNNs) become commonplace in powerful Artificial Intelligence (AI) systems, there has been a sharp increase in making DNNs interpretable by construction. *Concept representation Learning* (CL) \[[1](https://proceedings.mlr.press/v80/kim18d.html), [2](https://netdissect.csail.mit.edu/), [3](https://proceedings.mlr.press/v119/koh20a.html), [4](https://www.nature.com/articles/s42256-020-00265-z), [5](https://arxiv.org/abs/2209.09056), [6](https://arxiv.org/abs/2304.14068)\], a subfield in eXplainable AI (XAI), has emerged as a promising direction for designing high-performing interpretable neural architectures. At their core, CL methods learn an intermediate set of high-level *concept representations* (e.g., “stripped texture”, “round object”, etc.) from which they can predict a downstream task.

Driven by recent rich representations extracted from large datasets and models, CL has moved from a field constrained by the need for concept annotations to one where practical, powerful concept representations can be exploited without costly annotations. This tutorial aims to capitalise on the surge of interest in CL by equipping AI researchers and engineers with the necessary background to understand the current state of this body of work and build on it for their own research. Specifically, this tutorial will provide an overview of foundational and recent works in (i) **supervised concept learning**, (ii) **unsupervised concept learning**, and (iii) **concept-based neuro-symbolic reasoning**. We will conclude by highlighting several connections between CL and other areas in AI (e.g., disentanglement learning, representation learning, bias mitigation, etc.) and bringing forth key open questions within the field.

#### Required Background

Our material will assume a basic knowledge of ML (e.g., foundations of supervised learning, experimental design, basic probabilistic modelling, etc.), with particular emphasis on a solid Deep Learning foundation (e.g., tensor calculus, neural networks, backpropagation, etc.). Concepts that may require mathematical tools/expertise beyond those one would expect to be shared among the AAAI community will be (re)introduced in our tutorial.

All relevant material used and discussed during the tutorial, **including a recording of the tutorial**, will be made available [here](/tutorial).


## Important Details


- **Date**: This tutorial will be held on February 25, 2025 from 14:00 to 18:00.
- **Conference**: The Thirty-ninth Annual [AAAI Conference on Artificial Intelligence](https://aaai.org/conference/aaai/aaai-25/).
- **Location**: *Room 120A* of the Pennsylvania Convention Center, [Philadelphia, USA](https://g.co/kgs/Ttnk49V).
- **Modality**: In-person event with the option to join online via Underline (requires AAAI tutorial registration).


## Presenters
  <div class="row projects pt-1 pb-1" style="justify-content: center;">
      <div class="col-sm-4">
          {% include people.html name="Mateo Espinosa Zarlenga" affiliation="University of Cambridge" url="https://mateoespinosa.github.io/" img="/assets/img/people/mateo.jpg" %}
      </div>
      <div class="col-sm-4">
        {% include people.html name="Pietro Barbiero" affiliation="Università della Svizzera Italiana" url="https://www.pietrobarbiero.eu/" img="/assets/img/people/pietro.jpeg" %}
      </div>
  </div>


## Contact

For any questions, please do not hesitate to contact Mateo at
[me466@cam.ac.uk](mailto:me466@cam.ac.uk).
